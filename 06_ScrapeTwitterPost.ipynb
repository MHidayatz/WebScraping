{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84a2847-f411-4bcf-a623-d4837241f753",
   "metadata": {},
   "source": [
    "## Scraping Twitter Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfe3bfc-91dc-4735-a4d3-368c5c995db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "from getpass import getpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33d630e-04bc-4ca2-8ba7-93cf08a88035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starts the driver and goes to our starting webpage\n",
    "service = Service('C:/Users/user/OneDrive - 4y0flc/DataScience/Selenium-ChromeDriver/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Loginto twitter\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(2)\n",
    "\n",
    "# Setup the log in\n",
    "time.sleep(3)\n",
    "username = driver.find_element(By.XPATH,\"//input[@name='text']\")\n",
    "username.send_keys(\"mhidayatz86@gmail.com\")\n",
    "next_button = driver.find_element(By.XPATH,\"//span[contains(text(),'Next')]\")\n",
    "next_button.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4defcb-19eb-444e-a67e-aeea0a594f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block out if not required.\n",
    "# Retype username again\n",
    "time.sleep(3)\n",
    "username = driver.find_element(By.XPATH,\"//input[@name='text']\")\n",
    "username.send_keys(\"MdHiday99937419\")\n",
    "\n",
    "time.sleep(3)\n",
    "next_button = driver.find_element(By.XPATH,\"//span[contains(text(),'Next')]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370d656b-2d52-45a0-9b7c-f9bfe8aefdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ·········\n"
     ]
    }
   ],
   "source": [
    "# input Password\n",
    "my_password = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd99f934-16b1-4b54-8797-4b98ccfdb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Password\n",
    "time.sleep(3)\n",
    "password = driver.find_element(By.XPATH,\"//input[@name='password']\")\n",
    "password.send_keys(my_password)\n",
    "\n",
    "# Login Twitter\n",
    "time.sleep(3)\n",
    "log_in = driver.find_element(By.XPATH,\"//span[contains(text(),'Log in')]\")\n",
    "log_in.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70eb0ec9-9048-4514-b308-0f0dde7ae5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable that contains the celebirty or profile our program will scrape\n",
    "#This program will scrape Ryan Reynolds tweets as indicated in the line below\n",
    "subject = 'Ryan Reynolds'\n",
    "\n",
    "# Search item and fetch it\n",
    "time.sleep(3)\n",
    "search_box = driver.find_element(By.XPATH,\"//input[@data-testid='SearchBox_Search_Input']\")\n",
    "search_box.send_keys(subject)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "# Find the People button\n",
    "time.sleep(2)\n",
    "people = driver.find_element(By.XPATH,\"//span[contains(text(),'People')]\")\n",
    "people.click()\n",
    "\n",
    "# Click the first result in People\n",
    "time.sleep(2)\n",
    "profile = driver.find_element(By.XPATH,\"//*[@id='react-root']/div/div/div[2]/main/div/div/div/div/div/div[2]/div/section/div/div/div[1]/div/div/div/div/div[2]/div/div[1]/div/div[1]/a/div/div[1]/span/span\")\n",
    "profile.click()\n",
    "\n",
    "#Imports the HTML of the celebrities profile into python\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214397d4-3ca1-44af-9220-7a880aa91873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabs the HTML of each tweetl\n",
    "#ERROR WARNING! If there is an error try recopying the class attribute here, twitter may have changed it by like one or two letters whcih affects our code\n",
    "postings = soup.find_all('div', class_ = 'css-901oao r-1nao33i r-37j5jr r-a023e6 r-16dba41 r-rjixqe r-bcqeeo r-bnwqim r-qvutc0') \n",
    "\n",
    "#This loop will keep scrolling down the webpage loading in and collecting new tweets until we have scraped 100 unique tweets\n",
    "tweets = []\n",
    "TimeStamps = []\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "while True:\n",
    "    for post in postings:\n",
    "        tweets.append(post.text)\n",
    "\n",
    "    \n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "    time.sleep(3)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height    \n",
    "    \n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    #need to change the class here to match it with the other posting variable if there is an error\n",
    "    postings = soup.find_all('div', class_ = 'css-901oao r-1nao33i r-37j5jr r-a023e6 r-16dba41 r-rjixqe r-bcqeeo r-bnwqim r-qvutc0')\n",
    "    tweets2 = list(set(tweets))\n",
    "    if len(tweets2) > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5321b65c-53e1-4f23-ad17-8e401614d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(tweets)\n",
    "                  ,columns=['Tweets',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6da2c46f-2156-4ac4-bc95-1b4c4ea29ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this town. #WxmAFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s officially zero sleeps until opening day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With the actor at the center of the relationsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Season starts soon. The Red One. Now available.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We had a full medical team on standby in case ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hurry and stream your copy of Deadpool, Deadpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We’re supposed to announce Logan and Deadpool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No pressure. #WelcomeToWrexham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How has it been 20 years? #VanWilder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0                          I love this town. #WxmAFC\n",
       "1  It’s officially zero sleeps until opening day ...\n",
       "2  With the actor at the center of the relationsh...\n",
       "3  Season starts soon. The Red One. Now available.  \n",
       "4                                                   \n",
       "5  We had a full medical team on standby in case ...\n",
       "6  Hurry and stream your copy of Deadpool, Deadpo...\n",
       "7  We’re supposed to announce Logan and Deadpool ...\n",
       "8                     No pressure. #WelcomeToWrexham\n",
       "9               How has it been 20 years? #VanWilder"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5c6e0b-2377-49f1-a1af-55127c7e3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tweets_live.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
